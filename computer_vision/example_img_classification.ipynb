{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a8a46e",
   "metadata": {},
   "source": [
    "# Computer Vision - Image Classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609b338",
   "metadata": {},
   "source": [
    "###### Links: [Dog Breed (Kaggle)](https://www.kaggle.com/competitions/dog-breed-identification/overview)  |  [Article ()]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36ab50",
   "metadata": {},
   "source": [
    "### 0 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb4a63",
   "metadata": {},
   "source": [
    "###### Import pckgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203002fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1aa77260f7ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## for data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## for data\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook  import tqdm\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## for metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "## for cnn\n",
    "from tensorflow.keras import models, layers, utils, callbacks #(2.6.0)\n",
    "\n",
    "## for vit\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0399972",
   "metadata": {},
   "source": [
    "###### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"scottish_deerhound\", \"maltese_dog\", \"afghan_hound\", \"entlebucher\", \"bernese_mountain_dog\"]\n",
    "\n",
    "dtf = pd.read_csv(\"dogs_labels.csv\").rename(columns={\"breed\":\"label\"})\n",
    "dtf = dtf[dtf[\"label\"].isin(labels)].sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "dtf[\"y\"] = dtf[\"label\"].factorize(sort=True)[0]\n",
    "dic_y_mapping = dict( dtf[['y','label']].drop_duplicates().sort_values('y').values )\n",
    "print(dic_y_mapping)\n",
    "dtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9942f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirpath = \"data_dogs\"\n",
    "#for file in tqdm(os.listdir(dirpath)):\n",
    "#    filename = os.path.splitext(file)[0]\n",
    "#    if filename not in dtf[\"id\"].values:\n",
    "#        os.remove(os.path.join(dirpath, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load a single image with opencv.\n",
    "'''\n",
    "def utils_load_img(file, ext=['.png','.jpg','.jpeg','.JPG']):\n",
    "    if file.endswith(tuple(ext)):\n",
    "        img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "        if len(img.shape) > 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "    else:\n",
    "        print(\"file extension unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot a single image with pyplot.\n",
    ":parameter\n",
    "    :param img: image array\n",
    "    :param mask: image array\n",
    "    :param rect: list of tuples - [(x1,y1), (x2,y2)]\n",
    "    :param title: string\n",
    "'''\n",
    "def utils_plot_img(img, mask=None, rect=None, title=None, figsize=(5,3)):\n",
    "    plot_img = img.copy()\n",
    "    if mask is not None:\n",
    "        mask = cv2.resize(mask, (img.shape[0],img.shape[1]), interpolation=cv2.INTER_LINEAR)\n",
    "        plot_img = cv2.bitwise_and(plot_img, mask)\n",
    "    if rect is not None:\n",
    "        plot_img = cv2.rectangle(plot_img, rect[0], rect[1], (255,0,0), 4)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    if len(img.shape) > 2:\n",
    "        plt.imshow(plot_img)\n",
    "    else:\n",
    "        plt.imshow(plot_img, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot n images in (1 row) x (n columns).\n",
    "'''\n",
    "def plot_imgs(lst_imgs, lst_titles=[], figsize=(20,13)):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(lst_imgs), sharex=False, sharey=False, figsize=figsize)\n",
    "    if len(lst_titles) == 1:\n",
    "        fig.suptitle(lst_titles[0], fontsize=20)\n",
    "    for i,img in enumerate(lst_imgs):\n",
    "        ax[i].imshow(img)\n",
    "        if len(lst_titles) > 1:\n",
    "            ax[i].set(title=lst_titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try one\n",
    "img = utils_load_img(file=\"data_dogs/0042188c895a2f14ef64a918ed9c7b64.jpg\")\n",
    "utils_plot_img(img, title=\"shape: \"+str(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all\n",
    "dirpath = \"data_dogs\"\n",
    "ext=['.png','.jpg','.jpeg','.JPG']\n",
    "\n",
    "lst_imgs = []\n",
    "errors = 0\n",
    "for file in tqdm(sorted(os.listdir(dirpath))):\n",
    "    try:\n",
    "        if file.endswith(tuple(ext)):\n",
    "            img = utils_load_img(file=os.path.join(dirpath, file), ext=ext)\n",
    "            lst_imgs.append(img)\n",
    "    except Exception as e:\n",
    "        print(\"failed on:\", file, \"| error:\", e)\n",
    "        errors += 1\n",
    "        lst_imgs.append(np.nan)\n",
    "        pass\n",
    "\n",
    "dtf[\"img\"] = lst_imgs\n",
    "dtf = dtf[[\"id\",\"img\",\"label\",\"y\"]]\n",
    "print(\"check:\", len(lst_imgs), \"=\", len(dtf), \" |  Nas:\", errors, \"=\", dtf[\"img\"].isna().sum())\n",
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61219faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(dtf[\"img\"].head(), lst_titles=dtf[\"label\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a05be4",
   "metadata": {},
   "source": [
    "### 1 - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672e21a",
   "metadata": {},
   "source": [
    "###### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ce8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf[\"y\"].value_counts().plot(kind=\"barh\", title=\"Y\", figsize=(5,3)).grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d99c19",
   "metadata": {},
   "source": [
    "###### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = [img.shape[0] for img in dtf[\"img\"]]\n",
    "height = [img.shape[1] for img in dtf[\"img\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ac82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "\n",
    "## all\n",
    "ax[0].scatter(x=width, y=height, color=\"black\")\n",
    "ax[0].set(xlabel='width', ylabel=\"height\", title=\"Size distribution\")\n",
    "ax[0].grid()\n",
    "\n",
    "## zoom\n",
    "ax[1].scatter(x=width, y=height, color=\"black\")\n",
    "ax[1].set(xlabel='width', ylabel=\"height\", xlim=[100,700], ylim=[100,700], title=\"Zoom\")\n",
    "ax[1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (500,500)\n",
    "\n",
    "dtf[\"img\"] = [cv2.resize(img, img_size) for img in dtf[\"img\"]]\n",
    "plot_imgs(dtf[\"img\"].head(), lst_titles=dtf[\"y\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedf417",
   "metadata": {},
   "source": [
    "###### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1389a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = img_size+(3,)\n",
    "img_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f6f34",
   "metadata": {},
   "source": [
    "### 2 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb66226",
   "metadata": {},
   "source": [
    "###### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c489a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf[\"img\"] = dtf[\"img\"]/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24836c93",
   "metadata": {},
   "source": [
    "###### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf_train = dtf.head(500)\n",
    "dtf_test = dtf.tail(88)\n",
    "dtf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940318c4",
   "metadata": {},
   "source": [
    "###### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867297b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade95843",
   "metadata": {},
   "source": [
    "### 3 - Baseline (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4903ed9c",
   "metadata": {},
   "source": [
    "###### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4776cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input\n",
    "x_in = layers.Input(name=\"x_in\", shape=img_shape)\n",
    "\n",
    "## Conv + MaxPool\n",
    "x_conv2d = layers.Conv2D(name=\"x_conv2d\", filters=32, kernel_size=(3,3), activation=\"relu\")(x_in)\n",
    "x_maxpool = layers.MaxPooling2D(name='x_maxpool', pool_size=(2,2))(x_conv2d)\n",
    "\n",
    "## Conv + MaxPool\n",
    "x_conv2d2 = layers.Conv2D(name=\"x_conv2d2\", filters=32, kernel_size=(3,3), activation=\"relu\")(x_maxpool)\n",
    "x_maxpool2 = layers.MaxPooling2D(name='x_maxpool2', pool_size=(2,2))(x_conv2d2)\n",
    "\n",
    "## Flat + Dense\n",
    "flat = layers.Flatten(name=\"flat\")(x_maxpool2)\n",
    "dense = layers.Dense(name=\"dense\", units=128, activation='relu')(flat)\n",
    "\n",
    "## Output\n",
    "y_out = layers.Dense(name=\"y_out\", units=dtf_train[\"y\"].nunique(), activation=\"softmax\")(dense) #if binary -> 1 + sigmoid\n",
    "\n",
    "## Compile\n",
    "model = models.Model(inputs=x_in, outputs=y_out, name=\"CNN\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) #if binary -> n + binary_crossentropy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63177fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "model = models.Sequential(name=\"CNN\", layers=[\n",
    "    ## Conv + MaxPool\n",
    "    layers.Conv2D(name=\"x_conv2d\", input_shape=img_size+(3,), filters=32, kernel_size=(3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(name='x_maxpool', pool_size=(2,2)),\n",
    "    ## Conv + MaxPool\n",
    "    layers.Conv2D(name=\"x_conv2d2\", filters=32, kernel_size=(3,3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(name='x_maxpool2', pool_size=(2,2)),\n",
    "    ## Flat + Dense\n",
    "    layers.Flatten(name=\"flat\"),\n",
    "    layers.Dense(name=\"dense\", units=128, activation='relu'),\n",
    "    ## Output\n",
    "    layers.Dense(name=\"y_out\", units=dtf_train[\"y\"].nunique(), activation=\"softmax\") #if binary -> 1 + sigmoid\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) #if binary -> n + binary_crossentropy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86459f8f",
   "metadata": {},
   "source": [
    "###### Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot loss and metrics of keras training.\n",
    "'''\n",
    "def utils_plot_keras_training(training):\n",
    "    metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(15,3))\n",
    "    \n",
    "    ## training\n",
    "    ax[0].set(title=\"Training\")\n",
    "    ax11 = ax[0].twinx()\n",
    "    ax[0].plot(training.history['loss'], \"o-\", color='black')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss', color='black')\n",
    "    for metric in metrics:\n",
    "        ax11.plot(training.history[metric], \"o-\", label=metric)\n",
    "    ax11.set_ylabel(\"Score\", color='steelblue')\n",
    "    ax11.legend()\n",
    "    \n",
    "    ## validation\n",
    "    ax[1].set(title=\"Validation\")\n",
    "    ax22 = ax[1].twinx()\n",
    "    ax[1].plot(training.history['val_loss'], \"o-\", color='black')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss', color='black')\n",
    "    for metric in metrics:\n",
    "        ax22.plot(training.history['val_'+metric], \"o-\", label=metric)\n",
    "    ax22.set_ylabel(\"Score\", color=\"steelblue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7443e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "training = model.fit(x=np.array([x for x in dtf_train[\"img\"].values]), y=dtf_train[\"y\"].values, \n",
    "                     epochs=10, batch_size=64, shuffle=True, verbose=0, validation_split=0.2,\n",
    "                     callbacks=[callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)])\n",
    "model = training.model\n",
    "utils_plot_keras_training(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "predicted_prob = model.predict(np.array([x for x in dtf_test[\"img\"].values]))\n",
    "predicted = [np.argmax(pred) for pred in predicted_prob]\n",
    "\n",
    "dtf_test[\"yhat\"] = predicted\n",
    "dtf_test[\"pred\"] = dtf_test[\"yhat\"].apply(lambda x: dic_y_mapping[x])\n",
    "dtf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc2bd5",
   "metadata": {},
   "source": [
    "###### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ae1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluates a model performance.\n",
    ":parameter\n",
    "    :param y_test: array\n",
    "    :param predicted: array\n",
    "    :param predicted_prob: array\n",
    "    :param figsize: tuple - plot setting\n",
    "'''\n",
    "def evaluate_multi_classif(y_test, predicted, predicted_prob, figsize=(15,5)):\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "    \n",
    "    ## Accuracy, Precision, Recall\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    auc = metrics.roc_auc_score(y_test, predicted_prob, multi_class=\"ovr\")\n",
    "    print(\"Accuracy:\",  round(accuracy,2))\n",
    "    print(\"Auc:\", round(auc,2))\n",
    "    print(\"Detail:\")\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    \n",
    "    ## Plot confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, predicted)\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, cbar=False)\n",
    "    ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, yticklabels=classes, title=\"Confusion matrix\")\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
    "    ## Plot roc\n",
    "    for i in range(len(classes)):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i], predicted_prob[:,i])\n",
    "        ax[0].plot(fpr, tpr, lw=3, label='{0} (area={1:0.2f})'.format(classes[i], metrics.auc(fpr, tpr)))\n",
    "    ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "    ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05], xlabel='False Positive Rate', \n",
    "              ylabel=\"True Positive Rate (Recall)\", title=\"Receiver operating characteristic\")\n",
    "    ax[0].legend(loc=\"lower right\")\n",
    "    ax[0].grid(True)\n",
    "    \n",
    "    ## Plot precision-recall curve\n",
    "    for i in range(len(classes)):\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(y_test_array[:,i], predicted_prob[:,i])\n",
    "        ax[1].plot(recall, precision, lw=3, label='{0} (area={1:0.2f})'.format(classes[i], metrics.auc(recall, precision)))\n",
    "    ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall', ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    ax[1].grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_multi_classif(dtf_test[\"y\"].values, dtf_test[\"yhat\"].values, predicted_prob, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06abcd",
   "metadata": {},
   "source": [
    "### 4 - Model Desing & Testing (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26fab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9835469",
   "metadata": {},
   "source": [
    "### 5 - Model Desing & Testing (ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94a0ee",
   "metadata": {},
   "source": [
    "###### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd51a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = transformers.ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "vit(dtf[\"img\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f06295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = feature_extractor(images=image)\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = transformers.AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "model = transformers.AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdaf500",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFViTModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
